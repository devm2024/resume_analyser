{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as re\n",
    "from tqdm import *\n",
    "from ratelimiter import RateLimiter\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.com/r/Vidya-T/a834f22bf29502a2'\n",
    "this_content = re.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a834f22bf29502a2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_splits =url.split('/')\n",
    "urls_splits[len(urls_splits)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(this_content.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ceb85afcfbd5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'headline_location'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "a=soup.find('p', attrs={'id':'headline_location'})\n",
    "a.contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "@RateLimiter(max_calls=1, period=4)\n",
    "def get_resume(link, rb):\n",
    "    \n",
    "    this_content = re.get(url)\n",
    "    soup = BeautifulSoup(this_content.content,'html.parser')\n",
    "    \n",
    "    mydict= {}\n",
    "    mydict['rb']=rb\n",
    "    urls_splits =url.split('/')\n",
    "    mydict['id'] = urls_splits[len(urls_splits)-1]\n",
    "    mydict['summary_title'] = soup.find('h1', attrs={'class': 'fn'}).contents[0]\n",
    "    mydict['location']  = soup.find('p', attrs={'id':'headline_location'}).contents[0]\n",
    "    work_ex= soup.find('div',attrs={'id': 'work-experience-items'})\n",
    "    if len(work_ex.contents)>0:\n",
    "        mydict['current_job_company']= work_ex.contents[0].find('div', attrs= {'class':'work_company'}).contents[0].contents\n",
    "        mydict['current_job_title']= work_ex.contents[0].find('p', attrs={'class':'work_title title'}).contents[0]\n",
    "        mydict['current_job_desc'] = work_ex.contents[0].find('p', attrs={'class':'work_description'}).contents\n",
    "        mydict['current_job_duration'] = work_ex.contents[0].find('p', attrs={'class':'work_dates'}).contents[0]\n",
    "\n",
    "    if len(work_ex.contents)>1:\n",
    "        # Previous experience is available\n",
    "        mydict['prev_job_company']= work_ex.contents[1].find('div', attrs= {'class':'work_company'}).contents[0].contents\n",
    "        mydict['prev_job_title']= work_ex.contents[1].find('p', attrs={'class':'work_title title'}).contents[0]\n",
    "        mydict['prev_job_desc'] = work_ex.contents[1].find('p', attrs={'class':'work_description'}).contents\n",
    "        mydict['prev_job_duration'] = work_ex.contents[1].find('p', attrs={'class':'work_dates'}).contents[0]\n",
    "\n",
    "    work_duration_list=[]\n",
    "    # Get total work exp:\n",
    "    if len(work_ex.contents)>0:\n",
    "        for work in work_ex.contents:\n",
    "            this_duration = work.find('p', attrs={'class':'work_dates'}).contents[0]\n",
    "            work_duration_list.append(this_duration)\n",
    "\n",
    "    mydict['total_exp_durations'] = work_duration_list\n",
    "\n",
    "    educations = soup.find('div',attrs={'id': 'education-items'})\n",
    "    if len(educations.contents)>0:\n",
    "        mydict['education1_title']=educations.contents[0].find('p', attrs={'class':'edu_title'}).contents[0]\n",
    "        mydict['education1_college']=educations.contents[0].find('div', attrs={'class':'edu_school'}).contents[0].contents[0]\n",
    "        mydict['education1_duration']=educations.contents[0].find('p', attrs={'class':'edu_dates'}).contents[0]\n",
    "\n",
    "    if len(educations.contents)>1:\n",
    "        mydict['education2_title']=educations.contents[1].find('p', attrs={'class':'edu_title'}).contents[0]\n",
    "        mydict['education2_college']=educations.contents[1].find('div', attrs={'class':'edu_school'}).contents[0].contents[0]\n",
    "        mydict['education2_duration']=educations.contents[1].find('p', attrs={'class':'edu_dates'}).contents[0]\n",
    "\n",
    "    if len(educations.contents)>2:\n",
    "        mydict['education3_title']=educations.contents[2].find('p', attrs={'class':'edu_title'}).contents[0]\n",
    "        mydict['education3_college']=educations.contents[2].find('div', attrs={'class':'edu_school'}).contents[0].contents[0]\n",
    "        mydict['education3_duration']=educations.contents[2].find('p', attrs={'class':'edu_dates'}).contents[0]\n",
    "\n",
    "\n",
    "\n",
    "    # Skill\n",
    "    skill_list=[]\n",
    "    skills = soup.find('div',attrs={'id': 'skills-items'})\n",
    "    if skills is not None:\n",
    "        skill_set = skills.contents[0].contents[0].contents\n",
    "        if len(skill_set)>0:\n",
    "            for skill in skill_set:\n",
    "                try:\n",
    "                    skill_list.append(skill.contents)\n",
    "                except:\n",
    "                    pass\n",
    "    mydict['skils']=skill_list\n",
    "\n",
    "    # links\n",
    "    links_list=[]\n",
    "    links= soup.find('div',attrs={'id':'link-items'})\n",
    "    if links is not None:\n",
    "        links_set =links.contents\n",
    "        for link in links_set:\n",
    "            links_list.append(link.contents[0].contents[0].contents[0].contents[0])\n",
    "\n",
    "    mydict['links']=links_list\n",
    "\n",
    "\n",
    "    # additional_info\n",
    "    add_info = soup.find('div', attrs={'id':'additionalinfo-section'})\n",
    "    if add_info is not None:\n",
    "        mydict['additional_info']=add_info.contents[0].contents[0].contents\n",
    "\n",
    "\n",
    "    certi_list=[]\n",
    "    certifications = soup.find('div', attrs={'id':'certification-items'})\n",
    "    if certifications is not None:\n",
    "        for certi in certifications.contents:\n",
    "            certi_list.append(certi.contents[0].contents[0].contents[0])\n",
    "    mydict['certifications']=certi_list\n",
    "\n",
    "    award_list=[]\n",
    "    awards=soup.find('div', attrs={'id':'award-items'})\n",
    "    if awards is not None:\n",
    "        for one_award in awards:\n",
    "            award_list.append(one_award.contents[0].contents[0].contents[0])\n",
    "\n",
    "    mydict['awards'] = award_list\n",
    "    return mydict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>additional_info</th>\n",
       "      <th>awards</th>\n",
       "      <th>certifications</th>\n",
       "      <th>current_job_company</th>\n",
       "      <th>current_job_desc</th>\n",
       "      <th>current_job_duration</th>\n",
       "      <th>current_job_title</th>\n",
       "      <th>education1_college</th>\n",
       "      <th>education1_duration</th>\n",
       "      <th>education1_title</th>\n",
       "      <th>...</th>\n",
       "      <th>education2_title</th>\n",
       "      <th>id</th>\n",
       "      <th>links</th>\n",
       "      <th>prev_job_company</th>\n",
       "      <th>prev_job_desc</th>\n",
       "      <th>prev_job_duration</th>\n",
       "      <th>prev_job_title</th>\n",
       "      <th>skils</th>\n",
       "      <th>summary_title</th>\n",
       "      <th>total_exp_durations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[SKILLS , &lt;br/&gt;, •    Data Analytics Tools/Lan...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Booxby]</td>\n",
       "      <td>[•    Booxby is a machine learning platform so...</td>\n",
       "      <td>December 2017 to Present</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>University of Illinois at Urbana-Champaign, Ch...</td>\n",
       "      <td>August 2014 to August 2015</td>\n",
       "      <td>MS Business in Data Science</td>\n",
       "      <td>...</td>\n",
       "      <td>BA in Economics</td>\n",
       "      <td>404950f566637da6</td>\n",
       "      <td>[http://github.com/kellypeng]</td>\n",
       "      <td>[Gausscode Technology Inc]</td>\n",
       "      <td>[•    Worked as the company's first data analy...</td>\n",
       "      <td>February 2016 to May 2017</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>[[Amazon Elastic Compute Cloud (Less than 1 ye...</td>\n",
       "      <td>Data Scientist Intern</td>\n",
       "      <td>[December 2017 to Present, February 2016 to Ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     additional_info awards certifications  \\\n",
       "0  [SKILLS , <br/>, •    Data Analytics Tools/Lan...     []             []   \n",
       "\n",
       "  current_job_company                                   current_job_desc  \\\n",
       "0            [Booxby]  [•    Booxby is a machine learning platform so...   \n",
       "\n",
       "       current_job_duration      current_job_title  \\\n",
       "0  December 2017 to Present  Data Scientist Intern   \n",
       "\n",
       "                                  education1_college  \\\n",
       "0  University of Illinois at Urbana-Champaign, Ch...   \n",
       "\n",
       "          education1_duration             education1_title  \\\n",
       "0  August 2014 to August 2015  MS Business in Data Science   \n",
       "\n",
       "                         ...                         education2_title  \\\n",
       "0                        ...                          BA in Economics   \n",
       "\n",
       "                 id                          links  \\\n",
       "0  404950f566637da6  [http://github.com/kellypeng]   \n",
       "\n",
       "             prev_job_company  \\\n",
       "0  [Gausscode Technology Inc]   \n",
       "\n",
       "                                       prev_job_desc  \\\n",
       "0  [•    Worked as the company's first data analy...   \n",
       "\n",
       "           prev_job_duration prev_job_title  \\\n",
       "0  February 2016 to May 2017   Data Analyst   \n",
       "\n",
       "                                               skils          summary_title  \\\n",
       "0  [[Amazon Elastic Compute Cloud (Less than 1 ye...  Data Scientist Intern   \n",
       "\n",
       "                                 total_exp_durations  \n",
       "0  [December 2017 to Present, February 2016 to Ma...  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=[mydict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_links = pd.read_csv('links3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(   Unnamed: 0                                              links          rb\n",
       " 0           0  https://www.indeed.com/r/Tracy-Ruan/c47f7ac095...  6-10 years\n",
       " 1           1  https://www.indeed.com/r/Rebecca-Mashaido/b3fa...  6-10 years\n",
       " 2           2  https://www.indeed.com/r/Zhisheng-Lin/e307d3f4...  6-10 years\n",
       " 3           3  https://www.indeed.com/r/Tae-Hyon-Lee/f09d6780...  6-10 years\n",
       " 4           4  https://www.indeed.com/r/Wendy-Gao/1828f774d1c...  6-10 years,\n",
       " (11213, 3))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links.head(), all_links.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.indeed.com/r/Tracy-Ruan/c47f7ac095973653?sp=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'contents'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-865ba7ba7fb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a+'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m             \u001b[0mthis_parsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_resume\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'links'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/ratelimiter.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-51-bea640fbf388>\u001b[0m in \u001b[0;36mget_resume\u001b[0;34m(link, rb)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0murls_splits\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mmydict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murls_splits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murls_splits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mmydict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'fn'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmydict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'location'\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'headline_location'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mwork_ex\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'div'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'work-experience-items'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'contents'"
     ]
    }
   ],
   "source": [
    "all_resumes_parsed =[]\n",
    "for i, row in tqdm(all_links.iterrows()):\n",
    "    try:\n",
    "        with open('test.csv', 'a+') as f: \n",
    "            this_parsed = get_resume(row['links'], row['rb'])\n",
    "            if i==0:\n",
    "                w.writeheader()\n",
    "            w = csv.DictWriter(f, this_parsed.keys())\n",
    "            w.writerow(this_parsed)\n",
    "    except:\n",
    "        print(row['links'])\n",
    "        raise\n",
    "    all_resumes_parsed.append(this_parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ratelimiter import RateLimiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.indeed.com/r/Sherry-Kawing-Lau/d46d95cbdbacb8b3?sp=0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_links.loc[409]['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_resumes_parsed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-461b704af910>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_resumes_parsed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_resumes_parsed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_resumes_parsed' is not defined"
     ]
    }
   ],
   "source": [
    "all_resumes_parsed[len(all_resumes_parsed)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "my_dict = {\"test\": 4, \"testing\": 5}\n",
    "\n",
    "with open('test.csv', 'a+') as f:  # Just use 'w' mode in 3.x\n",
    "    w = csv.DictWriter(f, my_dict.keys())\n",
    "    #w.writeheader()\n",
    "    w.writerow(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

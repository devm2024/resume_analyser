{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as re\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.indeed.com/r/Data-Scientist-Intern/404950f566637da6'\n",
    "this_content = re.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'404950f566637da6'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls_splits =url.split('/')\n",
    "urls_splits[len(urls_splits)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(this_content.content,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict= {}\n",
    "urls_splits =url.split('/')\n",
    "mydict['id'] = urls_splits[len(urls_splits)-1]\n",
    "mydict['summary_title'] = soup.find('h1', attrs={'class': 'fn'}).contents[0]\n",
    "\n",
    "work_ex= soup.find('div',attrs={'id': 'work-experience-items'})\n",
    "if len(work_ex.contents)>0:\n",
    "    mydict['current_job_company']= work_ex.contents[0].find('div', attrs= {'class':'work_company'}).contents[0].contents\n",
    "    mydict['current_job_title']= work_ex.contents[0].find('p', attrs={'class':'work_title title'}).contents[0]\n",
    "    mydict['current_job_desc'] = work_ex.contents[0].find('p', attrs={'class':'work_description'}).contents\n",
    "    mydict['current_job_duration'] = work_ex.contents[0].find('p', attrs={'class':'work_dates'}).contents[0]\n",
    "    \n",
    "if len(work_ex.contents)>1:\n",
    "    # Previous experience is available\n",
    "    mydict['prev_job_company']= work_ex.contents[1].find('div', attrs= {'class':'work_company'}).contents[0].contents\n",
    "    mydict['prev_job_title']= work_ex.contents[1].find('p', attrs={'class':'work_title title'}).contents[0]\n",
    "    mydict['prev_job_desc'] = work_ex.contents[1].find('p', attrs={'class':'work_description'}).contents\n",
    "    mydict['prev_job_duration'] = work_ex.contents[1].find('p', attrs={'class':'work_dates'}).contents[0]\n",
    "    \n",
    "educations = soup.find('div',attrs={'id': 'education-items'})\n",
    "if len(educations.contents)>0:\n",
    "    mydict['education1_title']=educations.contents[0].find('p', attrs={'class':'edu_title'}).contents[0]\n",
    "    mydict['education1_college']=educations.contents[0].find('div', attrs={'class':'edu_school'}).contents[0].contents[0]\n",
    "    mydict['education1_duration']=educations.contents[0].find('p', attrs={'class':'edu_dates'}).contents[0]\n",
    "\n",
    "if len(educations.contents)>1:\n",
    "    mydict['education2_title']=educations.contents[1].find('p', attrs={'class':'edu_title'}).contents[0]\n",
    "    mydict['education2_college']=educations.contents[1].find('div', attrs={'class':'edu_school'}).contents[0].contents[0]\n",
    "    mydict['education2_duration']=educations.contents[1].find('p', attrs={'class':'edu_dates'}).contents[0]\n",
    "    \n",
    "if len(educations.contents)>2:\n",
    "    mydict['education3_title']=educations.contents[2].find('p', attrs={'class':'edu_title'}).contents[0]\n",
    "    mydict['education3_college']=educations.contents[2].find('div', attrs={'class':'edu_school'}).contents[0].contents[0]\n",
    "    mydict['education3_duration']=educations.contents[2].find('p', attrs={'class':'edu_dates'}).contents[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "# Skill\n",
    "skill_list=[]\n",
    "skills = soup.find('div',attrs={'id': 'skills-items'})\n",
    "if skills is not None:\n",
    "    skill_set = skills.contents[0].contents[0].contents\n",
    "    if len(skill_set)>0:\n",
    "        for skill in skill_set:\n",
    "            try:\n",
    "                skill_list.append(skill.contents)\n",
    "            except:\n",
    "                pass\n",
    "mydict['skils']=skill_list\n",
    "\n",
    "# links\n",
    "links_list=[]\n",
    "links= soup.find('div',attrs={'id':'link-items'})\n",
    "if links is not None:\n",
    "    links_set =links.contents\n",
    "    for link in links_set:\n",
    "        links_list.append(link.contents[0].contents[0].contents[0].contents[0])\n",
    "\n",
    "mydict['links']=links_list\n",
    "\n",
    "\n",
    "# additional_info\n",
    "add_info = soup.find('div', attrs={'id':'additionalinfo-section'})\n",
    "if add_info is not None:\n",
    "    mydict['additional_info']=add_info.contents[0].contents[0].contents\n",
    "\n",
    "\n",
    "certi_list=[]\n",
    "certifications = soup.find('div', attrs={'id':'certification-items'})\n",
    "if certifications is not None:\n",
    "    for certi in certifications.contents:\n",
    "        certi_list.append(certi.contents[0].contents[0].contents[0])\n",
    "mydict['certifications']=certi_list\n",
    "\n",
    "award_list=[]\n",
    "awards=soup.find('div', attrs={'id':'award-items'})\n",
    "if awards is not None:\n",
    "    for one_award in awards:\n",
    "        award_list.append(one_award.contents[0].contents[0].contents[0])\n",
    "        \n",
    "mydict['awards'] = award_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'additional_info': ['SKILLS\\xa0',\n",
       "  <br/>,\n",
       "  '•    Data Analytics Tools/Languages: SQL(PostgeSQL, MySQL), NoSQL(MongoDB), Python(Numpy,\\xa0',\n",
       "  <br/>,\n",
       "  'Pandas, Scipy, Scikit-learn, etc), R, Tableau, Spark, Hive, MapReduce, AWS(S3, EC2, EMR), Github\\xa0',\n",
       "  <br/>,\n",
       "  '•    Modeling and Statistical Analysis: Regression Analysis, Tree Based Models, kNN, Naive Bayes, Neural\\xa0',\n",
       "  <br/>,\n",
       "  'Networks, Clustering, PCA, SVD, NMF, Recommender Systems, Hypothesis Testing, Experimental Design'],\n",
       " 'awards': [],\n",
       " 'certifications': [],\n",
       " 'current_job_company': ['Booxby'],\n",
       " 'current_job_desc': ['•    Booxby is a machine learning platform solving the book discovery problem of publishing industry\\xa0',\n",
       "  <br/>,\n",
       "  '•    Leading the project of predicting the success of books to help publishers allocate marketing budget\\xa0',\n",
       "  <br/>,\n",
       "  '•    Using machine learning and natural language processing to help authors and publishers find the right market for their books, and help readers find the right books'],\n",
       " 'current_job_duration': 'December 2017 to Present',\n",
       " 'current_job_title': 'Data Scientist Intern',\n",
       " 'education1_college': 'University of Illinois at Urbana-Champaign, Champaign',\n",
       " 'education1_duration': 'August 2014 to August 2015',\n",
       " 'education1_title': 'MS Business in Data Science',\n",
       " 'education2_college': 'Wuhan University',\n",
       " 'education2_duration': 'September 2009 to June 2013',\n",
       " 'education2_title': 'BA in Economics',\n",
       " 'id': '404950f566637da6',\n",
       " 'links': ['http://github.com/kellypeng'],\n",
       " 'prev_job_company': ['Gausscode Technology Inc'],\n",
       " 'prev_job_desc': [\"•    Worked as the company's first data analyst, responsible for developing automatic data analytics product\\xa0\",\n",
       "  <br/>,\n",
       "  '•    Led the development of key metrics that allow clients monitor operation, visualized the metrics through 50+ reports and dashboards using MySQL and Tableau, frequently presented to senior management\\xa0',\n",
       "  <br/>,\n",
       "  \"•    Developed user personas for a retail industry client, stimulated client's sales through precision marketing\"],\n",
       " 'prev_job_duration': 'February 2016 to May 2017',\n",
       " 'prev_job_title': 'Data Analyst',\n",
       " 'skils': [['Amazon Elastic Compute Cloud (Less than 1 year)'],\n",
       "  ['APACHE HADOOP MAPREDUCE (Less than 1 year)'],\n",
       "  ['AWS (Less than 1 year)'],\n",
       "  ['data analytics (1 year)'],\n",
       "  ['MySQL (1 year)']],\n",
       " 'summary_title': 'Data Scientist Intern'}"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awards</th>\n",
       "      <th>certifications</th>\n",
       "      <th>current_job_company</th>\n",
       "      <th>current_job_desc</th>\n",
       "      <th>current_job_duration</th>\n",
       "      <th>current_job_title</th>\n",
       "      <th>education1_college</th>\n",
       "      <th>education1_duration</th>\n",
       "      <th>education1_title</th>\n",
       "      <th>education2_college</th>\n",
       "      <th>education2_duration</th>\n",
       "      <th>education2_title</th>\n",
       "      <th>id</th>\n",
       "      <th>links</th>\n",
       "      <th>prev_job_company</th>\n",
       "      <th>prev_job_desc</th>\n",
       "      <th>prev_job_duration</th>\n",
       "      <th>prev_job_title</th>\n",
       "      <th>skils</th>\n",
       "      <th>summary_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Stony Brook Turner Graduate Student Fellowshi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[Kickwheel (Formerly Schoold)]</td>\n",
       "      <td>[o    Engineered pipelines and developed hybri...</td>\n",
       "      <td>September 2017 to Present</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Stony Brook University</td>\n",
       "      <td>2014</td>\n",
       "      <td>PhD in Ecology and Evolution</td>\n",
       "      <td>New York University</td>\n",
       "      <td>2006</td>\n",
       "      <td>BA in Biology</td>\n",
       "      <td>6bfdff58f8024d3c</td>\n",
       "      <td>[http://www.linkedin.com/in/rociong]</td>\n",
       "      <td>[Schoold]</td>\n",
       "      <td>[o     Advised and aided product and engineeri...</td>\n",
       "      <td>September 2015 to September 2017</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>[[Python (3 years)], [R (4 years)], [Spark (Le...</td>\n",
       "      <td>Senior Data Scientist</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              awards certifications  \\\n",
       "0  [Stony Brook Turner Graduate Student Fellowshi...             []   \n",
       "\n",
       "              current_job_company  \\\n",
       "0  [Kickwheel (Formerly Schoold)]   \n",
       "\n",
       "                                    current_job_desc  \\\n",
       "0  [o    Engineered pipelines and developed hybri...   \n",
       "\n",
       "        current_job_duration      current_job_title      education1_college  \\\n",
       "0  September 2017 to Present  Senior Data Scientist  Stony Brook University   \n",
       "\n",
       "  education1_duration              education1_title   education2_college  \\\n",
       "0                2014  PhD in Ecology and Evolution  New York University   \n",
       "\n",
       "  education2_duration education2_title                id  \\\n",
       "0                2006    BA in Biology  6bfdff58f8024d3c   \n",
       "\n",
       "                                  links prev_job_company  \\\n",
       "0  [http://www.linkedin.com/in/rociong]        [Schoold]   \n",
       "\n",
       "                                       prev_job_desc  \\\n",
       "0  [o     Advised and aided product and engineeri...   \n",
       "\n",
       "                  prev_job_duration  prev_job_title  \\\n",
       "0  September 2015 to September 2017  Data Scientist   \n",
       "\n",
       "                                               skils          summary_title  \n",
       "0  [[Python (3 years)], [R (4 years)], [Spark (Le...  Senior Data Scientist  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=[mydict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'awards': ['Stony Brook Turner Graduate Student Fellowship',\n",
       "  'New York University Presidential Honors Scholarship'],\n",
       " 'certifications': [],\n",
       " 'current_job_company': ['Kickwheel (Formerly Schoold)'],\n",
       " 'current_job_desc': ['o    Engineered pipelines and developed hybrid recommendation models (content-based and collaborative filtering) in Spark(ML) for matching student users with relevant content (eg. schools, majors, and careers) based on implicit feedback and profile information \\xa0',\n",
       "  <br/>,\n",
       "  'o    Advised leadership and cross-functional collaborators on defining and tracking KPIs and metrics and utilizing product insights for driving product and business decisions\\xa0',\n",
       "  <br/>,\n",
       "  'o    Completed dashboards and product analytics projects, which included data visualizations and communication of findings pertaining to app engagement, retention, growth, user funnels etc. \\xa0',\n",
       "  <br/>,\n",
       "  'o    Made improvements to Spark ETL pipelines that processed raw analytics data, which led to an increase in performance and scalability, and enhanced abilities to do downstream data analysis, modeling, and machine learning \\xa0',\n",
       "  <br/>,\n",
       "  'o    Acted as product owner/manager for modules within the Kickwheel College Partner web portal and upcoming Kickwheel App. Developed prototypes, led ideation meetings, and collaborated with the engineering team during sprint ticketing and goal-setting'],\n",
       " 'current_job_duration': 'September 2017 to Present',\n",
       " 'current_job_title': 'Senior Data Scientist',\n",
       " 'education1_college': 'Stony Brook University',\n",
       " 'education1_duration': '2014',\n",
       " 'education1_title': 'PhD in Ecology and Evolution',\n",
       " 'education2_college': 'New York University',\n",
       " 'education2_duration': '2006',\n",
       " 'education2_title': 'BA in Biology',\n",
       " 'id': '6bfdff58f8024d3c',\n",
       " 'links': ['http://www.linkedin.com/in/rociong'],\n",
       " 'prev_job_company': ['Schoold'],\n",
       " 'prev_job_desc': ['o     Advised and aided product and engineering teams with implementation of data-driven features for in-app display of data and event tracking for in-app analytics\\xa0',\n",
       "  <br/>,\n",
       "  \"o     Developed an algorithm which utilizes probabilistic models for predicting a user's admissions\\xa0\",\n",
       "  <br/>,\n",
       "  'chances to a college/university based on standardized test scores and GPA\\xa0',\n",
       "  <br/>,\n",
       "  'o     Used a combination of machine learning (hierarchical clustering and multiple linear regression) and probabilistic models for the prediction of starting and mid-level salaries by major, degree level, and\\xa0',\n",
       "  <br/>,\n",
       "  'university/college\\xa0',\n",
       "  <br/>,\n",
       "  'o     Built and optimized data pipelines in Spark and Spark SQL for the ingestion and processing of raw\\xa0',\n",
       "  <br/>,\n",
       "  'json analytics data into Parquet tables and PostgreSQL databases\\xa0',\n",
       "  <br/>,\n",
       "  'o     Implemented natural language processing methods and pre-trained word2vec models for the improvement of in-app search functionality\\xa0',\n",
       "  <br/>,\n",
       "  'o     Developed recommendation models for matching student users with relevant content (eg. schools,\\xa0',\n",
       "  <br/>,\n",
       "  'scholarships) based on their profile information and activity in the application'],\n",
       " 'prev_job_duration': 'September 2015 to September 2017',\n",
       " 'prev_job_title': 'Data Scientist',\n",
       " 'skils': [['Python (3 years)'],\n",
       "  ['R (4 years)'],\n",
       "  ['Spark (Less than 1 year)'],\n",
       "  ['SQL (1 year)'],\n",
       "  ['HTML (1 year)']],\n",
       " 'summary_title': 'Senior Data Scientist'}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Carnegie Mellon University']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "educations.contents[0].find('div', attrs={'class':'edu_school'}).contents[0].contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Python (4 years)']\n",
      "['R programming (4 years)']\n",
      "['SQL (1 year)']\n"
     ]
    }
   ],
   "source": [
    "for c in soup.find('div',attrs={'id': 'skills-items'}).contents[0].contents[0].contents:\n",
    "    try:\n",
    "        print(c.contents)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SQL (1 year)']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
